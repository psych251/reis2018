---
title: "Replication of Study 5 by Reis et al. (2018, Journal of Experimental Social Psychology)"
author: "Catherine Garton (cgarton@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

### Background
Reis and colleagues (2018) reported a series of experiments that examine the interpersonal influences on intellectual humility (IH)^[IH can be thought of as the awareness of one's epistemic limitations, i.e., to what extent you understand that your beliefs might be wrong or may change in the future.]. IH is typically construed as a stable cognitive trait. However, the authors hypothesized that priming the social cue of partner responsiveness would boost IH, because feeling understood may decrease people's propensity for self-enhancement and allow them to respond to their environment more openly. Study 5, which I will attempt to replicate, finds that priming partner responsiveness promotes a broader cognitive perspective (as measured in a global-local visual orientation task).

### Justification
Intellectual humility has been the backbone of my research interests. The affective roots of IH are incredibly understudied, and I am hoping to explore the roles of threat and competition (vs. psychological safety and trust) in enabling intellectual humility about morally divisive or identity-based beliefs. This is the most relevant paper in the extant literature, because it provides preliminary evidence that feelings of safety and support increase cognitive openness.

### Stimuli and procedures
Participants will be recruited from Prolific and randomized to one of two conditions^[Note that this differs from the original study, in which there was also a neutral control. However, I am underpowered to examine three conditions, and the original effect was only found between the responsive and unresponsive conditions.]: responsive or unresponsive partner. In the responsive (vs. unresponsive) condition, participants are asked to describe 2 (vs. 10) kind or considerate things their partner had done for them in the past week. It is generally easy to think of 2 such examples and harder to think of 10; this relative availability primes confidence or doubt in one's partner's responsiveness. Then participants will complete 16 trials of the global-local visual orientation task (see example image below). Finally, participants will complete the 20-item PANAS measure of mood, a potential confounding variable. I expect the study to be programmable in Qualtrics and to take no longer than 10 minutes per participant.

<center>
![Fig. 1, Reis et al. (2018), p. 30](/Users/catherinegarton/Documents/Grad School/Class and admin/251/reis2018/images/global_local.png){width=50%}
</center>

```{r, echo=FALSE}
# I struggled with embedding this image. None of my relative file paths worked. I still need to figure out a better way of linking the image.

```

### Anticipated challenges
* Reaching appropriate power. The authors recruited 225 participants per condition (for a target of 188 after deletions) based on expected effect sizes. I may not have enough funding for 550 participants to take an 8-10 minute survey. (Update: I will re-assess this potential challenge after completing the power analysis.)
* Acquiring images for the global-local visual orientation task. I may need to contact the authors to obtain the images if I cannot obtain the high-quality files from public materials.

### Links
View the project repository on Github: [Psych 251 repo](https://github.com/psych251/reis2018){target="_blank"}

View the original paper: [Reis et al., 2018](https://github.com/psych251/reis2018/blob/main/original_paper/Reis_et_al_2018.pdf){target="_blank"}

View the replication survey: [Qualtrics](https://stanforduniversity.qualtrics.com/jfe/form/SV_783wI0qv7YyaeXA)

***

## Methods

### Power Analysis

TBD

### Planned Sample

Using Prolific, I will recruit English-speaking adults (*n* = TBD, based on power analysis). I will terminate data collection when I have reached the predetermined sample size, as indicated by my power analysis. There are no other pre-selection rules.

### Materials
Participants will view and select geometric images as part of a 16-trial global-local visual orientation task originally developed by Kimchi & Palmer (1982). Survey materials and images can be found on the [Harvard Dataverse](https://dataverse.harvard.edu/privateurl.xhtml?token=f8d2d590-6a8e-4df2-9dca-7e3f3813c78c). 

### Procedure	

To mimic the original study exactly, the study title will advertised as “relationships and perception”. Individuals who enroll in the study on Prolific will be redirected to a Qualtrics survey, where they will provide informed consent before continuing:

**1. Manipulation**:
Participants will first complete a writing prompt based on one of two randomized conditions. I will follow the original authors' procedure for the responsive (unresponsive) conditions:

> For the first part of the questionnaire, we are interested in how people think about their relationships and the world around them.
>
> Please complete this question in regard to **your romantic relationship partner** if you are **currently involved in a romantic relationship**, or in regard to a **close friend** if you are **not currently involved in a romantic relationship.**
>
> Please describe **2 (10) kind or considerate** things your relationship partner has done to help you **in the last 7 days.** 

**2. Global-local visual orientation task** (following Reis & colleagues' protocol exactly):

> On each trial, participants were shown a screen with a geometric shape (composed of triangles or squares) on top and beneath this single shape, two images containing multiple shapes. The participant is asked to judge whether the single shape is more similar to the lower-right or lower-left image. . . . Across trials, the right-left position of the global-local option was counterbalanced, as was the shape associated with each option. 
> (Reis et al., 2019, p. 29)

**3. Mood**:
After this task, participants will complete the 20-item PANAS (Watson, Clark, & Tellegen, 1988) to assess their mood.

**4. Attention check & demographics**:
Finally, participants will respond to a manipulation check (i.e., the ease or difficulty of the relationship recall task), an attention check, and a demographic question about their sex.


### Analysis Plan

#### Data cleaning 
Data will be excluded from analysis if any of the following criteria apply (according to reasons cited by the original authors):

* failing the attention check
* leaving the relationship recall task items blank
* skipping more than half of the global-local visual orientation trials
* choosing the same response on all 16 trials^[I don't understand the logic of this exclusion, but I am retaining it for consistency with the original paper]

#### Data processing
The independent variable, perceived responsiveness, will be captured by Qualtrics embedded data according to participants' randomized condition.

The dependent variable, cognitive broadening, will be calculated by summing the number of trials of which participants selected the "global processing" image (i.e., the image with pattern similarity rather than constituent-shape similarity). An alternative measure will be calculated by using the proportion of *completed* trials that reflect global processing, which will more accurately account for skipped trials.

A current mood score will be created by subtracting the mean score across negative items from the mean score across positive items. 

### Key analysis
The key analysis is a between-subjects pooled t-test on the global-processing mean scores between the responsive and unresponsive conditions. A significant mean difference, such that the responsive condition has higher global processing scores, would replicate the original finding. If a significant difference is found, I am also interested to see if the magnitude of the effect size is similar.

#### Additional analyses
Additional analyses will see if the effect persists after controlling for mood, as well as test for an interaction with participant sex, to see if the authors' other primary findings replicate.
For my own curiosity, I will also rerun all analyses without any data exclusions, as I perceive the authors' data exclusions to be a bit liberal!

### Differences from Original Study
1. In the original study, participants were not compensated for participating, whereas in this replication attempt, participants will be compensated monetarily. This is not expected to make a difference in the effect of interest. While participants might be differently motivated, this should not bias the effect in a particular direction.

2. This replication attempt is underpowered to support a 3rd condition (the neutral control), so it will only examine the difference between the responsive and unresponsive conditions, rather than conducting an ANOVA between all three. This will make a difference in the computation of the effect, given that I will end up conducting a t-test (which uses pooled variance from two groups) rather than the authors' post-hoc Fisher's LSD test (which would use the pooled variance from all three).

3. The authors included four additional questions^[These questions were: how often participants chose shapes based on constituent similarity, how often participants chose shapes based on pattern similarity, how difficult the relationship recall task was, and whether the participant had completed a similar relationship recall task before.] in their survey materials, which were not mentioned in the published article or included in the published analyses. These items are not part of the specific effect I am planning to replicate, so I am excluding them from the survey for the sake of time. Because these measures were collected after both the manipulation and DV task, they are not expected to make a difference in the effect of interest.

4. Depending on what Mike/the TAs think, I would prefer to use a different attention check. The authors had to exclude 1/3rd of their sample(!) for failing it, and this might leave me substantially underpowered. A consideration is that this change could impact the effect if there is something different about the people who would fail the authors' attention check but not a different one. This may be the case, given that the authors' attention check requires careful reading of a long block of text and might inadvertently favor people with focal visual orientation.

```{r notes to self, include=FALSE}
#NOTE: edit this for new attention check.
#NOTE: ask about forced choice
#NOTE: not mobile friendly yet
#NOTE: remove trial_17 from analysis!
```

### Methods Addendum (Post Data Collection)

TBD.

#### Actual Sample
  TBD.

#### Differences from pre-data collection methods plan
  TBD.


## Results

Note: I've included the analysis code below, which runs smoothly on the data. However, I haven't written any interpretation of these results yet, because the current data was randomly generated by non-naive participants and isn't meaningful.

### Data preparation
	
```{r, include=F}

####Load Relevant Libraries and Functions
library(here)

```

```{r warning=FALSE}

####Load Relevant Libraries and Functions
library(tidyverse)

```

```{r, warning=F}

####Import data
rawdata <- read_csv(here("data/rawdata/10-30-22.csv"))

###Data Preparation
rawdata <- rawdata[-(1:2),] # removing duplicate header rows that Qualtrics provides

#### Data exclusion / filtering
cleandata <- rawdata %>% 
  filter(Finished == 1 & attn_check_fruit == 1) %>% 
  select(
    -c(2:4, 7:22, 24, 26:29, 31)
  ) %>% 
  rename(duration = "Duration (in seconds)")

cleandata[,c(2, 8:46)] <- sapply(cleandata[,c(2, 8:46)], as.numeric)
cleandata[,"condition"] <- as.factor(cleandata$condition)
cleandata[,"gender"] <- as.factor(cleandata$gender)
cleandata[,"prior_knowledge_rrt"] <- as.factor(cleandata$prior_knowledge_rrt)
cleandata[,"prior_knowledge_pt"] <- as.factor(cleandata$prior_knowledge_pt)

# no one left more than half of the trials blank, skipped the recall task, or chose the same response on all 16 trials

  # manipulation check: difficulty of relationship recall task by condition
  test <- cleandata %>% select(c("condition", "difficulty", "difficulty_1")) %>% 
    unite("manip_check", c(difficulty, difficulty_1), na.rm=TRUE)
  
  t.test(as.numeric(manip_check) ~ condition, test)


#### Prepare data for analysis - create columns etc.
data <- cleandata %>% 
  mutate(global_sum = rowSums(select(cleandata, starts_with("trial_")), na.rm = TRUE)) %>% 
  mutate(global_prop = rowMeans(select(cleandata, starts_with("trial_")), na.rm = TRUE)) %>% 
  mutate(positive = rowMeans(cleandata[,c("panas_1", "panas_3", "panas_5", "panas_9", "panas_10", "panas_12", "panas_14", "panas_16", "panas_17", "panas_19")])) %>% 
  mutate(negative = rowMeans(cleandata[,c("panas_2", "panas_4", "panas_6", "panas_7", "panas_8", "panas_11", "panas_13", "panas_15", "panas_18", "panas_20")])) %>% 
  mutate(mood = positive - negative) %>% 
  unite("partner", c(partner_type, partner_type_1), na.rm=TRUE) %>%
  select(c("condition", "global_sum", "global_prop", "mood", "gender", "partner", "prior_knowledge_rrt", "prior_knowledge_pt", "attn_check_figure"))

```

### Confirmatory analysis

```{r}

t.test(global_sum ~ condition, data)
t.test(global_prop ~ condition, data)

plot(global_prop ~ condition, data = data,
        ylab = "global choice (prop. of trials)",
        main = "Global orientation by condition")

table <- data %>% 
  group_by(condition) %>% 
  summarize(global = mean(global_sum), sd = sd(global_sum, na.rm=T), n = n())
table

```

Compare to original table:
<center>
![Table 6, Reis et al. (2018), p. 30](/Users/catherinegarton/Documents/Grad School/Class and admin/251/reis2018/images/authortable.png){width=50%}
</center>

### Exploratory analyses

```{r }

summary(lm(global_prop ~ condition*mood, data))
summary(lm(global_prop ~ condition*gender, data))

```
